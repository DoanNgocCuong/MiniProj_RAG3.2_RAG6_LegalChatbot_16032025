{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Cursor Compose - Đóng Dockerfile và docker-compose.yml cho source frontend cũ để deploy port 30001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDant Free trước để upload Vector Database lên. \n",
    "```bash\n",
    "1 NODE\n",
    "DISK: 4GiB\n",
    "RAM: 1GiB\n",
    "vCPUs: 0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bổ sung1: Update UI cho đẹp\n",
    "@front-end \n",
    "Giữ nguyên mọi cái, đổi phông màu sang màu khác và biến nó thành UI, UX của nhà Apple, Iphone, Ipad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Cursor từ 2 file: format.md và LegalRAG_VECTOR_DATABASE_CREATE_EXCEL_LuatRAG.ipynb => viết thành .py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git commit -m \"Load Excel Data => Qdant embedding - page_content+metadata:(source, question)\n",
    "\n",
    "- Viết thêm 1 file test_qdant_connection.py (Cursor)\n",
    "- Loading data from backend_vector_database/dataset/LegalRAG.xlsx...\n",
    "Creating 85 document objects with metadata...\n",
    "Initializing embeddings with model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
    "Creating vector database in Qdrant collection: legal_rag\n",
    "Successfully added 85 documents to Qdrant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build Backend từ file pipeline của OpenWebUI trước mình build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chạy fastAPI để test real time ? log để xem bug ý "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To run the FastAPI application for real-time testing and view logs for debugging, I'll provide you with the commands and instructions to do this effectively.\n",
    "\n",
    "## Running FastAPI for Real-Time Testing\n",
    "\n",
    "Here are two approaches to run and test your FastAPI application:\n",
    "\n",
    "### Option 1: Run directly with Python\n",
    "\n",
    "````bash\n",
    "# Navigate to your backend directory\n",
    "cd src/back-end\n",
    "\n",
    "# Run the FastAPI application with debug logs\n",
    "python rag_backend.py\n",
    "````\n",
    "\n",
    "This will start the server on port 8000 as specified in your code, with auto-reload enabled for development.\n",
    "\n",
    "### Option 2: Run with Uvicorn directly (more control)\n",
    "\n",
    "````bash\n",
    "# Navigate to your backend directory\n",
    "cd src/back-end\n",
    "\n",
    "# Run with uvicorn with log level set to debug\n",
    "uvicorn rag_backend:app --host 0.0.0.0 --port 8000 --reload --log-level debug\n",
    "````\n",
    "\n",
    "## Viewing Logs\n",
    "\n",
    "The application already has print statements for debugging. To enhance logging:\n",
    "\n",
    "````python:src/back-end/rag_backend.py\n",
    "# Add this near the top of your file\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Output to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"rag-backend\")\n",
    "\n",
    "# Then replace print statements with logger calls\n",
    "# For example:\n",
    "# print(\"Initializing RAG Backend...\") becomes:\n",
    "logger.info(\"Initializing RAG Backend...\")\n",
    "# print(f\"Startup error: {str(e)}\") becomes:\n",
    "logger.error(f\"Startup error: {str(e)}\")\n",
    "````\n",
    "\n",
    "## Testing the API\n",
    "\n",
    "While the server is running, you can test it using the curl commands from your API_test.md file:\n",
    "\n",
    "````bash\n",
    "# Test with local RAG backend (port 8000)\n",
    "curl -X POST \"http://localhost:8000/v1/chat/completions\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": \"Quy tắc giao thông đường bộ là gì?\"}\n",
    "    ],\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "  }'\n",
    "````\n",
    "\n",
    "## Debugging Tips\n",
    "\n",
    "1. Check the FastAPI interactive docs at http://localhost:8000/docs when running locally\n",
    "2. Monitor the console output for errors and request processing logs\n",
    "3. Use the health endpoint to verify service status: `curl http://localhost:8000/health`\n",
    "4. For Docker container logs: `docker logs legal-rag-backend -f`\n",
    "\n",
    "These approaches will help you test in real-time and identify any bugs through the logs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Connect Backend với Frontend vì frontend đang xài cơ chế cũ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Phân tích Backend và Frontend\n",
    "\n",
    "## Backend\n",
    "\n",
    "Backend đang sử dụng **FastAPI** - một framework Python hiện đại để xây dựng API với hiệu suất cao:\n",
    "\n",
    "1. **Công nghệ chính**:\n",
    "   - FastAPI (framework API)\n",
    "   - Uvicorn (ASGI server)\n",
    "   - Qdrant (vector database)\n",
    "   - LangChain (framework RAG)\n",
    "   - OpenAI API (LLM)\n",
    "\n",
    "2. **Endpoint chính**:\n",
    "   - `/v1/chat/completions` - Endpoint chính để xử lý các yêu cầu chat\n",
    "   - `/health` - Endpoint kiểm tra trạng thái\n",
    "\n",
    "3. **Đặc điểm**:\n",
    "   - Cung cấp API tương thích với định dạng OpenAI\n",
    "   - Chạy trên port 30000\n",
    "   - Sử dụng Qdrant để tìm kiếm ngữ nghĩa\n",
    "\n",
    "## Frontend\n",
    "\n",
    "Frontend đang sử dụng **React** với **Vite** làm build tool:\n",
    "\n",
    "1. **Công nghệ chính**:\n",
    "   - React (thư viện UI)\n",
    "   - Vite (build tool)\n",
    "   - Tailwind CSS (framework CSS)\n",
    "   - React Router (quản lý routing)\n",
    "\n",
    "2. **Cấu trúc**:\n",
    "   - Có các trang: HomePage, FAQPage, IssuePage\n",
    "   - Component chính: ChatBot, NavBar\n",
    "\n",
    "## Phương thức giao tiếp\n",
    "\n",
    "Dựa trên code hiện tại, **phương thức giao tiếp giữa Frontend và Backend có thể chưa tương thích**:\n",
    "\n",
    "1. **Backend API**:\n",
    "   - Cung cấp endpoint `/v1/chat/completions` tương thích với OpenAI API\n",
    "   - Nhận và trả về dữ liệu theo định dạng OpenAI\n",
    "\n",
    "2. **Frontend**:\n",
    "   - Không thấy rõ code gọi API trong các file frontend\n",
    "   - Component ChatBot.jsx có thể đang sử dụng API khác\n",
    "\n",
    "## Điều chỉnh cần thiết\n",
    "\n",
    "Để đảm bảo frontend và backend có thể giao tiếp, cần:\n",
    "\n",
    "1. **Cập nhật ChatBot.jsx** để gọi đến API backend mới:\n",
    "\n",
    "```javascript\n",
    "// Thay đổi từ\n",
    "const response = await fetch('https://api.openai.com/v1/chat/completions', {\n",
    "  // ...\n",
    "});\n",
    "\n",
    "// Thành\n",
    "const response = await fetch('http://localhost:30000/v1/chat/completions', {\n",
    "  // ...\n",
    "});\n",
    "```\n",
    "\n",
    "2. **Cập nhật vite.config.js** để proxy API requests trong môi trường phát triển:\n",
    "\n",
    "```javascript\n",
    "export default defineConfig({\n",
    "  // ...\n",
    "  server: {\n",
    "    proxy: {\n",
    "      '/v1/chat/completions': {\n",
    "        target: 'http://localhost:30000',\n",
    "        changeOrigin: true,\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "});\n",
    "```\n",
    "\n",
    "3. **Cập nhật CORS trong backend** để cho phép frontend truy cập:\n",
    "\n",
    "```python\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\"],  # Vite dev server port\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```\n",
    "\n",
    "## Kết luận\n",
    "\n",
    "Backend và Frontend đang sử dụng các công nghệ hiện đại nhưng có thể chưa được cấu hình để giao tiếp với nhau. Cần cập nhật cả hai phía để đảm bảo chúng có thể hoạt động cùng nhau. Phương pháp tốt nhất là cập nhật frontend để gọi API backend mới, hoặc cập nhật backend để tương thích với API mà frontend đang sử dụng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Frontend API Integration Report\n",
    "\n",
    "## Current API Configuration\n",
    "\n",
    "After examining the frontend code, specifically the `ChatBot.jsx` component, I found that the frontend is currently making API requests to an ngrok endpoint:\n",
    "\n",
    "```javascript\n",
    "fetch(\"https://briefly-knowing-treefrog.ngrok-free.app/rag/\" + sourceData + \"?q=\" + promptInput,\n",
    "{\n",
    "  method: \"get\",\n",
    "  headers: new Headers({\n",
    "    \"ngrok-skip-browser-warning\": \"69420\",\n",
    "  }),\n",
    "})\n",
    "```\n",
    "\n",
    "## Issues Identified\n",
    "\n",
    "1. **Temporary ngrok URL**: The frontend is using a temporary ngrok URL (`briefly-knowing-treefrog.ngrok-free.app`) which will change when the ngrok session restarts.\n",
    "\n",
    "2. **No connection to Docker backend**: The frontend is not connecting to the Docker containerized backend service we've been configuring at port 30000.\n",
    "\n",
    "3. **Different API structure**: The current API endpoint structure (`/rag/{source}?q={query}`) doesn't match the OpenAI-compatible endpoint we've implemented in our backend (`/v1/chat/completions`).\n",
    "\n",
    "## Recommended Fixes\n",
    "\n",
    "1. **Update API endpoint to use the backend container**:\n",
    "\n",
    "```javascript\n",
    "// Replace this:\n",
    "fetch(\"https://briefly-knowing-treefrog.ngrok-free.app/rag/\" + sourceData + \"?q=\" + promptInput, ...)\n",
    "\n",
    "// With this (for local development):\n",
    "fetch(\"http://localhost:30000/v1/chat/completions\", {\n",
    "  method: \"POST\",\n",
    "  headers: {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "  },\n",
    "  body: JSON.stringify({\n",
    "    messages: [\n",
    "      {\"role\": \"user\", \"content\": promptInput}\n",
    "    ],\n",
    "    model: \"gpt-3.5-turbo\"\n",
    "  })\n",
    "})\n",
    "```\n",
    "\n",
    "2. **Update response handling**:\n",
    "   The current code expects a different response format than what our OpenAI-compatible API returns. We need to update the response handling to match our API's format.\n",
    "\n",
    "3. **Environment-based configuration**:\n",
    "   Add environment variables to configure the API URL based on the deployment environment (development, production, etc.).\n",
    "\n",
    "4. **Docker Compose for frontend and backend**:\n",
    "   Create a combined Docker Compose setup that includes both the frontend and backend services, with proper networking between them.\n",
    "\n",
    "These changes will ensure the frontend properly connects to our containerized backend service and handles the responses correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Fix lỗi connect backend với frontend -- mệt muón ngất - 2h-3h để fix lỗi này"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Chỉnh UI, UX: \n",
    "1. Thêm 1 dark mode\n",
    "- oke đó, dark mode tác động vào cả bên trong nữa đi \n",
    "- Để 3 câu hỏi tham khảo cho lần hỏi đầu tiên, và kéo dài thanh chat ra đi \n",
    "---\n",
    "Thêm Darkmode mé, xịn xò vãi chưởng"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
