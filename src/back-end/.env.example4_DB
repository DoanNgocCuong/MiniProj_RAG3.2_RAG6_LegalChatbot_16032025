# Cài đặt thông tin truy cập vector database
QDRANT_API_KEY=<QDRANT_API_KEY>
QDRANT_URL=<QDRANT_URL>

# Qdrant local
QDRANT_API_KEY=my_super_secret_key
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_URL = "http://localhost:6333"   # dùng cái này trong create DB để trấnh bị lỗi SSL
QDRANT_URL = "http://host.docker.internal:6333" 
# 1. Tương tự LLMs - Qdant và RAG là docker khác network nên cần internal để docker rag nó bắt được 6333 ở bên ngoài internal vào trong. (Chứ RAG ko thể localhost để bắt được vì RAG backend nó đang giao tiếp nội bộ với nhau)
# 2. Nếu nó chung network thì như: EMBEDDING, chỉ cần để EMBEDDING_API_URL=http://embedding-offline-service:8000
# 3. Còn nếu dùng localhost thì sao> nếu cả 2 đều export ra ngoài Docker thì có thể dùng localhost


# EMBEDDING MODEL
EMBEDDINGS_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
HUGGINGFACE_API_KEY=<HUGGINGFACE_API_KEY>

# Embedding Configuration
EMBEDDING_PROVIDER=offline  # "offline" hoặc "huggingface"
EMBEDDING_API_URL=http://embedding-offline-service:8000  # URL trong Docker network
# Đang dùng URL trong Docker network

# OPENAI API KEY FOR EMBEDDING AND CHAT
OPENAI_API_KEY=<OPENAI_API_KEY>

# Phải docker compose down, xong up --build -d tới tận 2 lần .env mới được load bằng cách theo lõi logs của docker backend

# LLM Provider Configuration
LLM_PROVIDER=local  # hoặc "openai"

# Các lựa chọn URL cho LOCAL_LLM_API_URL:
# 1. Dùng localhost trực tiếp (không được khi chạy trong container)
# LOCAL_LLM_API_URL=http://localhost:8001   # Ko được 

# 2. Dùng host.docker.internal để truy cập từ container tới máy host
LOCAL_LLM_API_URL=http://host.docker.internal:8001 

# 3. Nếu dùng chung 1 Docker network (vd: legal-network), thì:
# LOCAL_LLM_API_URL=http://llms-offline-service:8001
