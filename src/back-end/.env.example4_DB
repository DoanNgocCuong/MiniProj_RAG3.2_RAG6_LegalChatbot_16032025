# Cài đặt thông tin truy cập vector database
QDRANT_API_KEY=<QDRANT_API_KEY>
QDRANT_URL=<QDRANT_URL>

# Qdrant local
QDRANT_API_KEY=my_super_secret_key
QDRANT_HOST=localhost
QDRANT_PORT=6333

# EMBEDDING MODEL
EMBEDDINGS_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
HUGGINGFACE_API_KEY=<HUGGINGFACE_API_KEY>

# Embedding Configuration
EMBEDDING_PROVIDER=offline  # "offline" hoặc "huggingface"
EMBEDDING_API_URL=http://embedding-offline-service:8000  # URL trong Docker network
# Đang dùng URL trong Docker network

# OPENAI API KEY FOR EMBEDDING AND CHAT
OPENAI_API_KEY=<OPENAI_API_KEY>

# Phải docker compose down, xong up --build -d tới tận 2 lần .env mới được load bằng cách theo lõi logs của docker backend

# LLM Provider Configuration
LLM_PROVIDER=local  # hoặc "openai"

# Các lựa chọn URL cho LOCAL_LLM_API_URL:
# 1. Dùng localhost trực tiếp (không được khi chạy trong container)
# LOCAL_LLM_API_URL=http://localhost:8001   # Ko được 

# 2. Dùng host.docker.internal để truy cập từ container tới máy host
LOCAL_LLM_API_URL=http://host.docker.internal:8001 

# 3. Nếu dùng chung 1 Docker network (vd: legal-network), thì:
# LOCAL_LLM_API_URL=http://llms-offline-service:8001
