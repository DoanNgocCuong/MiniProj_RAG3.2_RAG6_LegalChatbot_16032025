# KHUYáº¾N NGHá»Š CUá»I CÃ™NG CHO Há»† THá»NG RAG TIáº¾NG VIá»†T

## Cáº¤U HÃŒNH MÃY CHO EMBEDDING VÃ€ LLM

### 1. Cáº¤U HÃŒNH Tá»I THIá»‚U Äá»‚ CHáº Y Cáº¢ EMBEDDING VÃ€ LLAMA-3.2-3B-INSTRUCT

```
ğŸ”¹ CPU: Intel Core i5 tháº¿ há»‡ 10 trá»Ÿ lÃªn / AMD Ryzen 5 3000 series trá»Ÿ lÃªn
ğŸ”¹ RAM: 16GB
ğŸ”¹ GPU: NVIDIA GPU vá»›i Ã­t nháº¥t 6GB VRAM (nhÆ° GTX 1660 Ti trá»Ÿ lÃªn)
ğŸ”¹ á»” cá»©ng: SSD 20GB trá»‘ng
ğŸ”¹ Há»‡ Ä‘iá»u hÃ nh: Windows 10/11 64-bit, Ubuntu 20.04 trá»Ÿ lÃªn
```

### 2. Cáº¤U HÃŒNH Äá»€ XUáº¤T CHO HIá»†U SUáº¤T Tá»T

```
ğŸ”¹ CPU: Intel Core i7/i9 tháº¿ há»‡ 11 trá»Ÿ lÃªn / AMD Ryzen 7/9 5000 series trá»Ÿ lÃªn
ğŸ”¹ RAM: 32GB
ğŸ”¹ GPU: NVIDIA RTX 3060 (8GB VRAM) trá»Ÿ lÃªn
ğŸ”¹ á»” cá»©ng: NVMe SSD vá»›i Ã­t nháº¥t 50GB trá»‘ng
ğŸ”¹ Há»‡ Ä‘iá»u hÃ nh: Windows 10/11 64-bit, Ubuntu 20.04 trá»Ÿ lÃªn
```

### 3. YÃŠU Cáº¦U RIÃŠNG CHO Tá»ªNG THÃ€NH PHáº¦N

| MÃ´ hÃ¬nh | CPU | RAM | GPU | á»” cá»©ng | Ghi chÃº |
|---------|-----|-----|-----|---------|---------|
| **AITeamVN/Vietnamese_Embedding** | Core i5/Ryzen 5 | 4-8GB | KhÃ´ng báº¯t buá»™c | 500MB | CÃ³ thá»ƒ cháº¡y CPU-only |
| **Llama-3.2-3B-Instruct-Frog** | Core i7/Ryzen 7 | 8-16GB | 6GB VRAM | 10GB | Tá»‘i Æ°u hiá»‡u suáº¥t vá»›i GPU |

## Lá»¢I ÃCH KHI Sá»¬ Dá»¤NG CÃC MÃ” HÃŒNH Äá»€ XUáº¤T

### AITeamVN/Vietnamese_Embedding

- **Hiá»‡u suáº¥t**: VÆ°á»£t trá»™i trong viá»‡c hiá»ƒu ngá»¯ nghÄ©a tiáº¿ng Viá»‡t
- **TÃ i nguyÃªn**: Nháº¹ hÆ¡n cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ (768 chiá»u thay vÃ¬ 1024)
- **Äá»‹nh lÆ°á»£ng**: ÄÆ°á»£c tinh chá»‰nh cho má»¥c Ä‘Ã­ch RAG tiáº¿ng Viá»‡t

### Llama-3.2-3B-Instruct-Frog

- **CÃ¢n báº±ng**: Äáº¡t cÃ¢n báº±ng tá»‘t giá»¯a kÃ­ch thÆ°á»›c vÃ  hiá»‡u suáº¥t
- **Ngá»¯ cáº£nh**: CÃ³ thá»ƒ xá»­ lÃ½ ngá»¯ cáº£nh dÃ i cho RAG
- **Tá»‘i Æ°u hÃ³a**: PhiÃªn báº£n GGUF Ä‘Æ°á»£c tá»‘i Æ°u cho CPU vÃ  GPU yÃªu cáº§u tháº¥p

## HÆ¯á»šNG DáºªN TRIá»‚N KHAI Tá»I Æ¯U

### 1. Thiáº¿t láº­p mÃ´i trÆ°á»ng

```bash
# Táº¡o mÃ´i trÆ°á»ng conda
conda create -n rag_env python=3.10
conda activate rag_env

# CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t
pip install sentence-transformers torch langchain qdrant_client llama-cpp-python uvicorn fastapi
```

### 2. Táº£i vÃ  cÃ i Ä‘áº·t mÃ´ hÃ¬nh embedding

```python
from sentence_transformers import SentenceTransformer

# Táº¡o thÆ° má»¥c lÆ°u mÃ´ hÃ¬nh
import os
os.makedirs("models/embedding", exist_ok=True)

# Táº£i mÃ´ hÃ¬nh Vietnamese_Embedding
model = SentenceTransformer("AITeamVN/Vietnamese_Embedding", cache_folder="models/embedding")

# Kiá»ƒm tra
test_embedding = model.encode("Kiá»ƒm tra mÃ´ hÃ¬nh embedding tiáº¿ng Viá»‡t")
print(f"KÃ­ch thÆ°á»›c vector: {len(test_embedding)}")
```

### 3. CÃ i Ä‘áº·t mÃ´ hÃ¬nh LLM 3B

```bash
# Táº£i mÃ´ hÃ¬nh GGUF Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u
mkdir -p models/llm
wget -O models/llm/llama-3.2-3B-instruct-frog-Q5_K_M.gguf https://huggingface.co/TheBloke/Llama-3.2-3B-Instruct-GGUF/resolve/main/llama-3.2-3b-instruct.Q5_K_M.gguf
```

### 4. Thiáº¿t láº­p dá»‹ch vá»¥ embedding

```python
# embedding_service.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Union
from sentence_transformers import SentenceTransformer
import uvicorn

app = FastAPI()
model_path = "AITeamVN/Vietnamese_Embedding"
cache_dir = "models/embedding"

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
model = SentenceTransformer(model_path, cache_folder=cache_dir)

class EmbeddingRequest(BaseModel):
    texts: Union[str, List[str]]

@app.post("/embed")
def create_embedding(request: EmbeddingRequest):
    try:
        texts = request.texts if isinstance(request.texts, list) else [request.texts]
        embeddings = model.encode(texts)
        return {"embeddings": embeddings.tolist()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("embedding_service:app", host="0.0.0.0", port=8001)
```

### 5. Thiáº¿t láº­p dá»‹ch vá»¥ LLM

```python
# llm_service.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import uvicorn
from llama_cpp import Llama

app = FastAPI()
model_path = "models/llm/llama-3.2-3B-instruct-frog-Q5_K_M.gguf"

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh vá»›i tá»‘i Æ°u hÃ³a cho GPU
model = Llama(
    model_path=model_path,
    n_ctx=4096,  # Ngá»¯ cáº£nh dÃ i cho RAG
    n_gpu_layers=-1,  # Tá»± Ä‘á»™ng dÃ¹ng háº¿t GPU layers
    n_threads=4  # Äiá»u chá»‰nh theo sá»‘ lÃµi CPU
)

class GenerationRequest(BaseModel):
    prompt: str
    max_tokens: int = 1024
    temperature: float = 0.7

@app.post("/generate")
def generate_text(request: GenerationRequest):
    try:
        output = model.create_completion(
            request.prompt, 
            max_tokens=request.max_tokens,
            temperature=request.temperature
        )
        return {"generated_text": output["choices"][0]["text"]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("llm_service:app", host="0.0.0.0", port=8002)
```

### 6. Docker Compose Ä‘á»ƒ Äiá»u phá»‘i cÃ¡c Dá»‹ch vá»¥

```yaml
version: '3'

services:
  embedding:
    build: 
      context: ./embedding
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./models/embedding:/app/models/embedding
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  llm:
    build:
      context: ./llm
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    volumes:
      - ./models/llm:/app/models/llm
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 12G
    environment:
      - CUDA_VISIBLE_DEVICES=0

  rag-backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      - embedding
      - llm
    environment:
      - EMBEDDING_URL=http://embedding:8001
      - LLM_URL=http://llm:8002

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - ./data/qdrant:/qdrant/storage
```

## TIP Bá»” SUNG

### 1. Tá»‘i Æ°u hÃ³a vá»›i GPU háº¡n cháº¿ (4-6GB VRAM)

```python
# Sá»­ dá»¥ng bá»™ nhá»› ná»­a chÃ­nh xÃ¡c
model = Llama(
    model_path=model_path,
    n_gpu_layers=-1,
    n_threads=4,
    n_batch=512,  # Giáº£m kÃ­ch thÆ°á»›c batch
    f16_kv=True,  # Sá»­ dá»¥ng bá»™ nhá»› ná»­a chÃ­nh xÃ¡c cho KV cache
    use_mlock=False
)
```

### 2. LÆ°u trá»¯ mÃ´ hÃ¬nh trÃªn á»• Ä‘Ä©a cháº­m (HDD)

CÃ¡ch tá»• chá»©c dá»¯ liá»‡u Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t:
- Táº¡o bá»™ nhá»› Ä‘á»‡m trÃªn RAM hoáº·c SSD cho pháº§n Ä‘Æ°á»£c truy cáº­p thÆ°á»ng xuyÃªn
- LÆ°u trá»¯ toÃ n bá»™ mÃ´ hÃ¬nh trÃªn HDD
- Khi khá»Ÿi Ä‘á»™ng, sao chÃ©p vÃ o bá»™ nhá»› Ä‘á»‡m

```python
import shutil
import os

# ÄÆ°á»ng dáº«n mÃ´ hÃ¬nh trÃªn HDD
hdd_model_path = "/mnt/hdd/models/vietnamese_embedding"

# ÄÆ°á»ng dáº«n bá»™ nhá»› Ä‘á»‡m trÃªn SSD
ssd_cache_path = "/tmp/models/embedding"

# Sao chÃ©p file quan trá»ng sang SSD khi khá»Ÿi Ä‘á»™ng
os.makedirs(ssd_cache_path, exist_ok=True)
for file in ["config.json", "modules.json", "1_Pooling/config.json", "pytorch_model.bin"]:
    src = os.path.join(hdd_model_path, file)
    dst = os.path.join(ssd_cache_path, file)
    if os.path.exists(src):
        os.makedirs(os.path.dirname(dst), exist_ok=True)
        shutil.copy(src, dst)

# Sá»­ dá»¥ng mÃ´ hÃ¬nh tá»« bá»™ nhá»› Ä‘á»‡m
model = SentenceTransformer(ssd_cache_path)
```

## LÆ¯U Ã QUAN TRá»ŒNG

1. **Quáº£n lÃ½ bá»™ nhá»› GPU**: Náº¿u cháº¡y cáº£ LLM vÃ  mÃ´ hÃ¬nh embedding trÃªn cÃ¹ng GPU, hÃ£y Ä‘áº·t thÃ´ng sá»‘ `max_memory` Ä‘á»ƒ kiá»ƒm soÃ¡t bá»™ nhá»› VRAM cho tá»«ng mÃ´ hÃ¬nh

2. **Bá»™ nhá»› Ä‘á»‡m embeddings**: CÃ¢n nháº¯c lÆ°u trá»¯ vÃ  cache embeddings cho vÄƒn báº£n thÆ°á»ng xuyÃªn sá»­ dá»¥ng Ä‘á»ƒ trÃ¡nh tÃ­nh toÃ¡n láº¡i

3. **Láº­p lá»‹ch batch**: Vá»›i nguá»“n lá»±c háº¡n cháº¿, xá»­ lÃ½ nhiá»u yÃªu cáº§u nhá» cÃ¹ng lÃºc hiá»‡u quáº£ hÆ¡n má»™t yÃªu cáº§u lá»›n

4. **Äá»‹nh lÆ°á»£ng mÃ´ hÃ¬nh**: GGUF Q5_K_M Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng tá»‘t giá»¯a cháº¥t lÆ°á»£ng vÃ  dung lÆ°á»£ng bá»™ nhá»›. Náº¿u RAM/VRAM háº¡n cháº¿, hÃ£y dÃ¹ng Q4_K_M

Vá»›i cáº¥u hÃ¬nh mÃ¡y Ä‘Æ°á»£c Ä‘á» xuáº¥t, báº¡n cÃ³ thá»ƒ cháº¡y cáº£ Vietnamese_Embedding vÃ  mÃ´ hÃ¬nh LLM 3B má»™t cÃ¡ch hiá»‡u quáº£, Ä‘áº£m báº£o pháº£n há»“i nhanh cho há»‡ thá»‘ng RAG cá»§a mÃ¬nh.




----


# ÄÃNH GIÃ LENOVO LEGION 5 PRO CHO Há»† THá»NG RAG

TÃ´i Ä‘Ã£ kiá»ƒm tra máº«u [Lenovo Legion 5 Pro Core i7-13650HX, 16GB, 1TB, RTX 4060 8GB, 16 inch WQXGA 240Hz](https://mac24h.vn/lenovo-legion-5-pro-core-i7-13650hx-16gb-1tb-rtx-4060-8gb-16-inch-wqxga-240hz.html) vÃ  Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cháº¡y Vietnamese_Embedding vÃ  LLM 3B:

## THÃ”NG Sá» Ká»¸ THUáº¬T & ÄÃNH GIÃ

| ThÃ nh pháº§n | ThÃ´ng sá»‘ | ÄÃ¡nh giÃ¡ cho RAG |
|------------|----------|-----------------|
| **CPU** | Intel Core i7-13650HX (14 nhÃ¢n, 20 luá»“ng) | âœ… **XUáº¤T Sáº®C** - CPU tháº¿ há»‡ 13 máº¡nh máº½, nhiá»u nhÃ¢n (6P+8E) |
| **RAM** | 16GB DDR5 | âš ï¸ **Äá»¦ DÃ™NG** - Khuyáº¿n nghá»‹ nÃ¢ng cáº¥p lÃªn 32GB |
| **GPU** | NVIDIA RTX 4060 8GB VRAM | âœ… **XUáº¤T Sáº®C** - CÃ³ thá»ƒ cháº¡y tá»‘t cáº£ LLM 3B vÃ  embedding |
| **á»” cá»©ng** | SSD NVMe 1TB | âœ… **Tá»T** - Äá»§ khÃ´ng gian cho cÃ¡c mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u |
| **MÃ n hÃ¬nh** | 16" WQXGA (2560x1600) 240Hz | âœ… **Tá»T** - KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t AI |
| **Há»‡ thá»‘ng táº£n nhiá»‡t** | Legion Coldfront 5.0 | âœ… **Tá»T** - GiÃºp duy trÃ¬ hiá»‡u suáº¥t trong cÃ¡c tÃ¡c vá»¥ náº·ng |

## KHáº¢ NÄ‚NG CHáº Y CÃC MÃ” HÃŒNH

### 1. AITeamVN/Vietnamese_Embedding
- **Káº¿t quáº£**: âœ… **CHáº Y Ráº¤T Tá»T**
- **Hiá»‡u suáº¥t dá»± kiáº¿n**: Táº£i mÃ´ hÃ¬nh trong vÃ i giÃ¢y, táº¡o embedding trong thá»i gian thá»±c
- **RAM sá»­ dá»¥ng**: ~2-4GB
- **VRAM sá»­ dá»¥ng** (náº¿u trÃªn GPU): ~2GB
- **Thá»i gian pháº£n há»“i Æ°á»›c tÃ­nh**: <50ms/cÃ¢u

### 2. Llama-3.2-3B-Instruct-Frog
- **Káº¿t quáº£**: âœ… **CHáº Y Ráº¤T Tá»T**
- **Hiá»‡u suáº¥t dá»± kiáº¿n**: ~30-40 token/giÃ¢y vá»›i GPU
- **RAM sá»­ dá»¥ng**: ~8-10GB
- **VRAM sá»­ dá»¥ng**: ~6GB
- **Ngá»¯ cáº£nh tá»‘i Ä‘a**: CÃ³ thá»ƒ xá»­ lÃ½ ngá»¯ cáº£nh 4K tokens

### 3. Kháº£ nÄƒng cháº¡y Ä‘á»“ng thá»i
- **Káº¿t quáº£**: âœ… **CÃ“ THá»‚ CHáº Y Äá»’NG THá»œI**
- Vá»›i 8GB VRAM, báº¡n cÃ³ thá»ƒ phÃ¢n bá»•:
  - ~2GB VRAM cho embedding
  - ~6GB VRAM cho LLM

## ÄIá»‚M Máº NH & Háº N CHáº¾

### Äiá»ƒm máº¡nh
- **GPU RTX 4060 8GB** - CÃ³ kiáº¿n trÃºc Ada Lovelace vÃ  há»— trá»£ tá»‘t cÃ¡c tÃ¡c vá»¥ AI
- **CPU i7-13650HX 14 nhÃ¢n** - Xá»­ lÃ½ Ä‘a luá»“ng máº¡nh máº½, táº§n sá»‘ turbo cao
- **SSD NVMe 1TB** - Tá»‘c Ä‘á»™ Ä‘á»c/ghi nhanh, giÃºp táº£i mÃ´ hÃ¬nh nhanh chÃ³ng
- **Há»‡ thá»‘ng táº£n nhiá»‡t tá»‘t** - GiÃºp duy trÃ¬ hiá»‡u suáº¥t trong thá»i gian dÃ i
- **Cá»•ng káº¿t ná»‘i Ä‘áº§y Ä‘á»§** - Thuáº­n tiá»‡n Ä‘á»ƒ má»Ÿ rá»™ng

### Háº¡n cháº¿
- **RAM 16GB** - Äá»§ dÃ¹ng nhÆ°ng khÃ´ng dÆ° dáº£ Ä‘á»ƒ cháº¡y nhiá»u á»©ng dá»¥ng song song
- **VRAM 8GB** - Äá»§ cho mÃ´ hÃ¬nh LLM 3B nhÆ°ng sáº½ lÃ  giá»›i háº¡n náº¿u muá»‘n nÃ¢ng lÃªn 7B

## KHUYáº¾N NGHá»Š

1. **NÃ¢ng cáº¥p RAM**: Bá»• sung thÃªm 16GB RAM (lÃªn 32GB) sáº½ giÃºp há»‡ thá»‘ng á»•n Ä‘á»‹nh hÆ¡n khi cháº¡y nhiá»u á»©ng dá»¥ng Ä‘á»“ng thá»i

2. **Chiáº¿n lÆ°á»£c triá»ƒn khai tá»‘i Æ°u**:
   - Sá»­ dá»¥ng GPU cho cáº£ embedding vÃ  LLM vá»›i sá»± phÃ¢n bá»• VRAM há»£p lÃ½
   - Sá»­ dá»¥ng mÃ´ hÃ¬nh GGUF Ä‘á»‹nh lÆ°á»£ng Q5_K_M cho LLM Ä‘á»ƒ tiáº¿t kiá»‡m VRAM
   - CÃ¢n nháº¯c dockerize cÃ¡c dá»‹ch vá»¥ Ä‘á»ƒ quáº£n lÃ½ tÃ i nguyÃªn tá»‘t hÆ¡n

3. **LÆ°u Ã½ khi sá»­ dá»¥ng**:
   - LuÃ´n káº¿t ná»‘i nguá»“n Ä‘iá»‡n khi cháº¡y cÃ¡c tÃ¡c vá»¥ AI náº·ng
   - Äáº·t laptop trÃªn bá» máº·t cá»©ng, thoÃ¡ng Ä‘á»ƒ táº£n nhiá»‡t tá»‘t nháº¥t
   - Sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ nhÆ° MSI Afterburner Ä‘á»ƒ theo dÃµi nhiá»‡t Ä‘á»™ GPU

## Káº¾T LUáº¬N

Lenovo Legion 5 Pro vá»›i i7-13650HX vÃ  RTX 4060 8GB lÃ  má»™t lá»±a chá»n **XUáº¤T Sáº®C** Ä‘á»ƒ cháº¡y há»‡ thá»‘ng RAG vá»›i Vietnamese_Embedding vÃ  mÃ´ hÃ¬nh LLM 3B. Laptop nÃ y hoÃ n toÃ n Ä‘Ã¡p á»©ng vÃ  vÆ°á»£t trá»™i so vá»›i yÃªu cáº§u tá»‘i thiá»ƒu Ä‘Ã£ Ä‘á» cáº­p.

Vá»›i viá»‡c nÃ¢ng cáº¥p RAM lÃªn 32GB (chi phÃ­ khoáº£ng 1-1.5 triá»‡u Ä‘á»“ng), báº¡n sáº½ cÃ³ má»™t mÃ¡y tÃ­nh máº¡nh máº½ cÃ³ thá»ƒ cháº¡y tá»‘t cÃ¡c mÃ´ hÃ¬nh AI vÃ  cÃ²n cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng lÃªn cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n náº¿u cáº§n trong tÆ°Æ¡ng lai.